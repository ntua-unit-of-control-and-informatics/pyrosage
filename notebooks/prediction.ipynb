{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T11:43:08.046819Z",
     "start_time": "2025-05-21T11:43:08.039450Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "from AttentiveFP import save_smiles_dicts, get_smiles_array"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T11:43:08.123802Z",
     "start_time": "2025-05-21T11:43:08.115015Z"
    }
   },
   "source": [
    "model_details_df = pd.read_csv('../data/model_details.csv', index_col= 'index')\n",
    "raw_filename = \"../data/dataset.csv\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T11:43:08.225788Z",
     "start_time": "2025-05-21T11:43:08.180184Z"
    }
   },
   "source": [
    "for best_name in model_details_df.index:\n",
    "\n",
    "    batch_size = 128\n",
    "    fingerprint_dim = model_details_df['fingerprint_dim']['{}'.format(best_name)]\n",
    "    radius = model_details_df['radius']['{}'.format(best_name)]\n",
    "    T = model_details_df['T']['{}'.format(best_name)]\n",
    "    moddel_path = model_details_df['model_path']['{}'.format(best_name)]\n",
    "    model = torch.load(model_details_df['model_path']['{}'.format(best_name)])\n",
    "    output_units_num = 1\n",
    "\n",
    "    feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "    filename = raw_filename.replace('.csv','')\n",
    "    smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "    smilesList = smiles_tasks_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "    smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "    assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "    smilesList = [smiles for smiles in canonical_smiles_list]\n",
    "\n",
    "    if os.path.isfile(feature_filename):\n",
    "        feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "    else:\n",
    "        feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "    remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "\n",
    "    model.eval()\n",
    "    preList = np.arange(0,remained_df.shape[0])\n",
    "    batch_list = []\n",
    "    y_pred_label=[]\n",
    "    for i in range(0, remained_df.shape[0], batch_size):\n",
    "        batch = preList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "    for counter, pre_batch in enumerate(batch_list):\n",
    "        batch_df = remained_df.loc[pre_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction, _ = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        \n",
    "        mol_prediction_np = mol_prediction.cpu()\n",
    "        y_pred_label.append(mol_prediction_np.detach().numpy())\n",
    "    y_pred_label_list = [i[0] for item in y_pred_label for i in item]\n",
    "    remained_df['y_pred_label'] = y_pred_label_list\n",
    "    remained_df.to_csv(\"../results/labeled_{}.csv\".format(best_name),mode = 'a',index =False)"
   ],
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001B[1mdo those steps only if you trust the source of the checkpoint\u001B[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL AttentiveFP.AttentiveLayers.Fingerprint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([AttentiveFP.AttentiveLayers.Fingerprint])` or the `torch.serialization.safe_globals([AttentiveFP.AttentiveLayers.Fingerprint])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m T \u001B[38;5;241m=\u001B[39m model_details_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(best_name)]\n\u001B[1;32m      7\u001B[0m moddel_path \u001B[38;5;241m=\u001B[39m model_details_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_path\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(best_name)]\n\u001B[0;32m----> 8\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_details_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m output_units_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     11\u001B[0m feature_filename \u001B[38;5;241m=\u001B[39m raw_filename\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.pickle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/ntua/pyrosage/.venv/lib/python3.10/site-packages/torch/serialization.py:1524\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1516\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[1;32m   1517\u001B[0m                     opened_zipfile,\n\u001B[1;32m   1518\u001B[0m                     map_location,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1521\u001B[0m                     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[1;32m   1522\u001B[0m                 )\n\u001B[1;32m   1523\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1524\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[1;32m   1526\u001B[0m             opened_zipfile,\n\u001B[1;32m   1527\u001B[0m             map_location,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1530\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[1;32m   1531\u001B[0m         )\n\u001B[1;32m   1532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n",
      "\u001B[0;31mUnpicklingError\u001B[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001B[1mdo those steps only if you trust the source of the checkpoint\u001B[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL AttentiveFP.AttentiveLayers.Fingerprint was not an allowed global by default. Please use `torch.serialization.add_safe_globals([AttentiveFP.AttentiveLayers.Fingerprint])` or the `torch.serialization.safe_globals([AttentiveFP.AttentiveLayers.Fingerprint])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cd4ab3795b19bcaabc245b3de58fc014c4a91b397e1a8c471ec940ed1b3eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
